{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bec0eda",
   "metadata": {},
   "source": [
    "### Creating a test set from validation set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- config ---\n",
    "VOC_PATH = \"./data/VOCdevkit/VOC2012\"\n",
    "IMAGE_DIR = os.path.join(VOC_PATH, \"JPEGImages\")\n",
    "MASK_DIR = os.path.join(VOC_PATH, \"SegmentationClass\")\n",
    "SPLIT_DIR = os.path.join(VOC_PATH, \"ImageSets\", \"Segmentation\")\n",
    "\n",
    "TRAIN_FILE = os.path.join(SPLIT_DIR, \"train.txt\")\n",
    "VAL_FILE = os.path.join(SPLIT_DIR, \"val.txt\")\n",
    "TEST_FILE = os.path.join(SPLIT_DIR, \"test.txt\")\n",
    "\n",
    "# --- for checking ---\n",
    "if not os.path.exists(VAL_FILE):\n",
    "    raise FileNotFoundError(\"val.txt not found.\")\n",
    "if os.path.exists(TEST_FILE):\n",
    "    raise FileExistsError(\"test.txt already exists.\")\n",
    "\n",
    "# --- Load id files ---\n",
    "with open(TRAIN_FILE, \"r\") as f:\n",
    "    train_ids = [line.strip() for line in f]\n",
    "\n",
    "with open(VAL_FILE, \"r\") as f:\n",
    "    val_ids = [line.strip() for line in f]\n",
    "\n",
    "if len(val_ids) != 1449:\n",
    "    raise ValueError(f\"Expected 1449 val IDs, but found {len(val_ids)}\")\n",
    "\n",
    "# --- split val to val + test ---\n",
    "test_ids = val_ids[-450:]\n",
    "val_ids = val_ids[:-450]\n",
    "\n",
    "# --- WRITE UPDATED FILES ---\n",
    "with open(VAL_FILE, \"w\") as f:\n",
    "    f.write(\"\\n\".join(val_ids) + \"\\n\")\n",
    "with open(TEST_FILE, \"w\") as f:\n",
    "    f.write(\"\\n\".join(test_ids) + \"\\n\")\n",
    "\n",
    "# --- filter imgs nd masks to match train + val + test ---\n",
    "final_ids = set(train_ids + val_ids + test_ids)\n",
    "all_images = os.listdir(IMAGE_DIR)\n",
    "all_masks = os.listdir(MASK_DIR)\n",
    "\n",
    "deleted = 0\n",
    "for img_file in all_images:\n",
    "    img_id = os.path.splitext(img_file)[0]\n",
    "    if img_id not in final_ids:\n",
    "        os.remove(os.path.join(IMAGE_DIR, img_file))\n",
    "        deleted += 1\n",
    "\n",
    "for mask_file in all_masks:\n",
    "    mask_id = os.path.splitext(mask_file)[0]\n",
    "    if mask_id not in final_ids:\n",
    "        os.remove(os.path.join(MASK_DIR, mask_file))\n",
    "        deleted += 1\n",
    "\n",
    "# --- FINAL CHECK ---\n",
    "print(f\"\\ntest.txt created with {len(test_ids)} IDs.\")\n",
    "print(f\"val.txt updated with {len(val_ids)} IDs.\")\n",
    "print(f\"\\n Final counts:\")\n",
    "print(f\"Train IDs: {len(train_ids)}\")\n",
    "print(f\"Val IDs:   {len(val_ids)}\")\n",
    "print(f\"Test IDs:  {len(test_ids)}\")\n",
    "print(f\"Total kept image-mask pairs: {len(final_ids)}\")\n",
    "print(f\"Expected pairs to keep:      {len(train_ids) + len(val_ids) + len(test_ids)}\")\n",
    "print(f\"Deleted {deleted} files (images + masks not in splits).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8018632",
   "metadata": {},
   "source": [
    "### Creating Class Distribution Plot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from dataset import PascalVOCDataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "data_dir = \"./data/VOCdevkit/VOC2012\"\n",
    "num_classes = 21\n",
    "image_height, image_width = 256, 256\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(height=image_height, width=image_width),\n",
    "    ToTensorV2(),\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "image_dir = os.path.join(data_dir, \"JPEGImages\")\n",
    "mask_dir = os.path.join(data_dir, \"SegmentationClass\")\n",
    "train_split_file = os.path.join(data_dir, \"ImageSets\", \"Segmentation\", \"train.txt\")\n",
    "test_split_file = os.path.join(data_dir, \"ImageSets\", \"Segmentation\", \"val.txt\")\n",
    "\n",
    "train_dataset = PascalVOCDataset(image_dir, mask_dir, train_split_file, transform=transform)\n",
    "test_dataset = PascalVOCDataset(image_dir, mask_dir, test_split_file, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "def count_pixels(loader):\n",
    "    counts = torch.zeros(num_classes, dtype=torch.long)\n",
    "    for _, mask in tqdm(loader):\n",
    "        for c in range(num_classes):\n",
    "            counts[c] += (mask == c).sum()\n",
    "    return counts\n",
    "\n",
    "train_counts = count_pixels(train_loader).numpy()\n",
    "test_counts = count_pixels(test_loader).numpy()\n",
    "\n",
    "index = np.arange(num_classes)\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(index - bar_width/2, train_counts, bar_width, label='Train')\n",
    "plt.bar(index + bar_width/2, test_counts, bar_width, label='Test')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Pixel Count (log scale)')\n",
    "plt.title('Class Pixel Distribution (Train vs Test)')\n",
    "plt.xticks(index)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee60f8",
   "metadata": {},
   "source": [
    "### Unique labels in train set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to your train.txt split file\n",
    "split_file = \"/content/data/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"  # update this\n",
    "mask_dir = \"/content/data/VOCdevkit/VOC2012/SegmentationClass\"  # update this\n",
    "\n",
    "# Read all image ids\n",
    "with open(split_file, 'r') as f:\n",
    "    image_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "unique_labels = set()\n",
    "\n",
    "for img_id in tqdm(image_ids):\n",
    "    mask_path = os.path.join(mask_dir, f\"{img_id}.png\")\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    unique_labels.update(np.unique(mask).tolist())\n",
    "\n",
    "print(\"Unique labels found in train masks:\", sorted(unique_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bf62a",
   "metadata": {},
   "source": [
    "### Checking 1 image class no. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dfd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "\n",
    "\n",
    "data_dir = \"/content/data/VOCdevkit/VOC2012\" \n",
    "\n",
    "mask_dir = os.path.join(data_dir, \"SegmentationClass\")\n",
    "train_split_file = os.path.join(data_dir, \"ImageSets\", \"Segmentation\", \"train.txt\")\n",
    "\n",
    "# Read a list of mask filenames from the train split file\n",
    "mask_filenames = []\n",
    "with open(train_split_file, 'r') as f:\n",
    "    for line in f:\n",
    "        \n",
    "        image_id = line.strip()\n",
    "        mask_filenames.append(f\"{image_id}.png\") # Masks are typically .png\n",
    "\n",
    "if not mask_filenames:\n",
    "    print(f\"No mask filenames found in {train_split_file}. \")\n",
    "else:\n",
    "    # Load the first mask found to inspect its class numbers\n",
    "    sample_mask_filename = mask_filenames[0]\n",
    "    sample_mask_path = os.path.join(mask_dir, sample_mask_filename)\n",
    "\n",
    "    if os.path.exists(sample_mask_path):\n",
    "        print(f\"Loading sample mask: {sample_mask_path}\")\n",
    "        mask_image = Image.open(sample_mask_path).convert('L') # Convert to grayscale \n",
    "        mask_array = np.array(mask_image)\n",
    "\n",
    "        unique_classes = np.unique(mask_array)\n",
    "        print(f\"Unique class numbers in sample mask '{sample_mask_filename}': {unique_classes}\")\n",
    "        print(f\"Minimum class number: {np.min(unique_classes)}\")\n",
    "        print(f\"Maximum class number: {np.max(unique_classes)}\")\n",
    "\n",
    "        # Check for 255 specifically\n",
    "        if 255 in unique_classes:\n",
    "            print(\"Class 255 (ignore index) is present in this sample mask.\")\n",
    "    else:\n",
    "        print(f\"Sample mask not found at: {sample_mask_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171006a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image # Pillow for loading images\n",
    "from collections import Counter\n",
    "from tqdm import tqdm # For progress bar\n",
    "\n",
    "# Assume your data_dir is the same as in train.py\n",
    "data_dir = \"/content/data/VOCdevkit/VOC2012\" # Replace if different\n",
    "\n",
    "mask_dir = os.path.join(data_dir, \"SegmentationClass\")\n",
    "train_split_file = os.path.join(data_dir, \"ImageSets\", \"Segmentation\", \"train.txt\")\n",
    "\n",
    "print(f\"Checking class imbalance for masks in: {mask_dir}\")\n",
    "print(f\"Using mask list from: {train_split_file}\")\n",
    "\n",
    "all_pixel_counts = Counter()\n",
    "\n",
    "# Read a list of mask filenames from the train split file\n",
    "mask_filenames = []\n",
    "try:\n",
    "    with open(train_split_file, 'r') as f:\n",
    "        for line in f:\n",
    "            image_id = line.strip()\n",
    "            mask_filenames.append(f\"{image_id}.png\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Train split file not found at {train_split_file}\")\n",
    "    exit()\n",
    "\n",
    "if not mask_filenames:\n",
    "    print(\"No mask filenames found to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate through all masks with a progress bar\n",
    "for filename in tqdm(mask_filenames, desc=\"Counting pixels per class\"):\n",
    "    mask_path = os.path.join(mask_dir, filename)\n",
    "    if not os.path.exists(mask_path):\n",
    "        # print(f\"Warning: Mask not found for {filename}. Skipping.\")\n",
    "        continue # Skip if file doesn't exist\n",
    "\n",
    "    try:\n",
    "        mask_image = Image.open(mask_path).convert('L') # Convert to grayscale\n",
    "        mask_array = np.array(mask_image)\n",
    "\n",
    "        # Count pixel occurrences in this mask\n",
    "        # np.bincount is efficient for integer counts\n",
    "        # Ensure max value for bincount is large enough (e.g., 255)\n",
    "        counts = np.bincount(mask_array.flatten(), minlength=256) # Max possible class ID is 255\n",
    "\n",
    "        # Add to overall counts\n",
    "        for class_id, count in enumerate(counts):\n",
    "            if count > 0:\n",
    "                all_pixel_counts[class_id] += count\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing mask {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n--- Class Pixel Distribution ---\")\n",
    "total_pixels = sum(all_pixel_counts.values())\n",
    "\n",
    "if total_pixels == 0:\n",
    "    print(\"No pixels counted. Make sure masks are loaded correctly.\")\n",
    "else:\n",
    "    # Sort by class ID for cleaner output\n",
    "    sorted_class_ids = sorted(all_pixel_counts.keys())\n",
    "\n",
    "    for class_id in sorted_class_ids:\n",
    "        count = all_pixel_counts[class_id]\n",
    "        percentage = (count / total_pixels) * 100\n",
    "        label_name = f\"Class {class_id}\"\n",
    "        if class_id == 0:\n",
    "            label_name = \"Class 0 (Background)\"\n",
    "        elif class_id == 255:\n",
    "            label_name = \"Class 255 (Ignore/Void)\"\n",
    "        print(f\"{label_name: <25}: {count: <10} pixels ({percentage:.4f}%)\")\n",
    "\n",
    "    # Optionally, calculate percentage for actual training classes (excluding 0 and 255)\n",
    "    training_pixels_sum = 0\n",
    "    for class_id in sorted_class_ids:\n",
    "        if class_id != 0 and class_id != 255:\n",
    "            training_pixels_sum += all_pixel_counts[class_id]\n",
    "\n",
    "    if training_pixels_sum > 0:\n",
    "        print(\"\\n--- Distribution of Actual Foreground Classes (Excluding Background and Ignore) ---\")\n",
    "        for class_id in sorted_class_ids:\n",
    "            if class_id != 0 and class_id != 255:\n",
    "                count = all_pixel_counts[class_id]\n",
    "                percentage = (count / training_pixels_sum) * 100\n",
    "                print(f\"Class {class_id: <15}: {count: <10} pixels ({percentage:.4f}%)\")\n",
    "    else:\n",
    "        print(\"\\nNo foreground classes (excluding 0 and 255) found or counted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5839f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65baff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7101e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
